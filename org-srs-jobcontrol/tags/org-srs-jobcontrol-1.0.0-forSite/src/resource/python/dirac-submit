#!/usr/bin/env python
# S.Zimmer 10/2012 The Oskar Klein Center for Cosmoparticle Physics

class options:
    def __init__(self,DICT,**kwargs):
        self.RTE = None
        self.cpu = 64000
        self.site = None
        self.stagein = None
        self.name = None
        self.debug = False
        self.env = None
        self.outputsandbox = None
        self.__dict__.update(DICT)
        self.__dict__.update(kwargs)

def setSpecialOption( optVal ):
    from DIRAC import S_OK
    global specialOptions
    option,value = optVal.split('=')
    specialOptions[option] = value
    return S_OK()

def extract_inputfiles(fname):
    file_list = []
    lines = open(fname,'read').readlines()
    for line in lines:
        thisLine = line.replace("\n","")
        file_list.append(thisLine)
    return file_list

if __name__ == "__main__":

    import sys
    from DIRAC.Core.Base import Script
    specialOptions = {}
    Script.registerSwitch( "p:", "parameter=", "Special option (currently supported: RTE, cpu, site, stagein, name, debug, env, outputsandbox) ", setSpecialOption )
    Script.parseCommandLine()
    args = Script.getPositionalArgs() 
    from DIRAC.Interfaces.API.Job import Job
    from DIRAC.Interfaces.API.Dirac import Dirac

    opts = options(specialOptions) # converts the "DIRAC registerSwitch()" to something similar to OptionParser
    #print opts.__dict__
    #sys.exit()
    j = Job()

    input_sandbox_files = ['']
    pipeline_dict = None
    if not pipeline_dict is None and pipeline_dict.has_key("GPL_CONFIGDIR"):
        GPL_CONFIGDIR = pipeline_dict['GPL_CONFIGDIR']
        if os.path.isdir(GPL_CONFIGDIR):
            files = os.listdir(GPL_CONFIGDIR)
            for f in files:
                input_sandbox_files.append(f)
    if not opts.env is None:
        import json
        f = open(specialOptions["env"],"r")
        pipeline_dict = json.load(f)

        # this is a temporary bugfix for https://jira.slac.stanford.edu/browse/LPG-6
        new_dict = {}
        forbidden_values = [";" , "=" , " " , "\t"]
        for key in pipeline_dict.keys():
            include = True
            for var in forbidden_values:
                if var in str(pipeline_dict[key]):
                    include = False
            if include:
                new_dict[key]=str(pipeline_dict[key])
        pipeline_dict = new_dict
        # end of the bugfix

        j.setExecutionEnv(pipeline_dict) # that sets the env vars
        input_sandbox_files.append("pipeline_wrapper") # if pipeline envs exist, export wrapper file

    if len(args)>0:
        executable = args[0]
        j.setExecutable(executable)
    j.setName("MC job")
    if not opts.name is None:
        j.setName(opts.name)

    j.setInputSandbox(input_sandbox_files) # all input files in the sandbox

    if not opts.outputsandbox is None:
        j.setOutputSandbox(opts.outputsandbox)

    j.setCPUTime(opts.cpu)
    if not opts.RTE is None:
        j._addJDLParameter("other.GlueHostApplicationSoftwareRunTimeEnvironment",opts.RTE)

    if not opts.site is None:
        j.setDestination(opts.site)

    if not opts.stagein is None:
        input_stage_files = []
        # we do add. input staging
        files = opts.stagein.split(",")
        for f in files:
            if f.startswith("LFN"):
                input_stage_files.append(f)
            else:
                input_stage_files+=extract_file(f)
        for f in input_stage_files:
            if not f.startswith("LFN"):
                raise Exception("*ERROR* required inputfiles to be defined through LFN, could not find LFN in %s"%f)
        j.setInputData(input_stage_files)

    if opts.debug:
        print '*DEBUG* just showing the JDL of the job to be submitted'
        print j._toJDL()
    else:
        try:
            d = Dirac()
        except AttributeError:
            raise Exception("Error loading Dirac monitor")

        print "Your job %s (\"%s\") has been submitted."%(str(d.submit(j)['Value']),executable)
                                                         
